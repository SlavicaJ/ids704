---
title: "Structural Topic Modeling"
output:
  html_document:
    toc: true
    toc_depth: 5
---

<br>
**[Text as Data Course](https://cbail.github.io/textasdata/Text_as_Data.html)**   
**Chris Bail, PhD**  
**Duke University**  
[www.chrisbail.net](http://www.chrisbail.net)  
[github.com/cbail](https://github.com/cbail)  
[twitter.com/chris_bail](https://twitter.com/chris_bail)   

## Structural Topic Modeling

LDA is but one of many different types of topic modeling. Though LDA is perhaps the most common form of topic modeling, a number of associated techniques now exist, including Dynamic Topic Models, Correlated Topic Models, Hierarchical Topic Models, and so on. One of the most increasingly popular techniques to emerge in recent years, however, is Structural Topic Modeling, or STM. STM is very similar to LDA, but it employs meta data about documents (such as the name of the author or the date in which the document was produced) to improve the assignment of words to latent topics in a corpus. For a more detailed discussion of the technical implementation of STM, see [this paper](https://cran.r-project.org/web/packages/stm/vignettes/stmVignette.pdf), which analyzes the same dataset we will employ below.

Another major advantage of STM is that there is a very high quality R package to implement this package called `stm`. This package is not only useful for performing STM, but for validating topic models, determining the appropriate value of `k` and visualizing or further inrpreting topic models. It even includes a handy function for pre-proceessing text. Let's take a look at an overview of the methods in the `stm` package produced by the package's authors:

![](stm_diagram.png)

Let's work with some new data that is a .csv file that describes 13,254 posts on six political blogs from 2008 that are employed in the `stm` package vignette. These data were collected by [Einstein and Xing](http://www.sailing.cs.cmu.edu/main/socialmedia/blog2008.pdf). You can download this large .csv file as follows:

```{r}
google_doc_id <- "1LcX-JnpGB0lU1iDnXnxB6WFqBywUKpew" # google file ID
poliblogs<-read.csv(sprintf("https://docs.google.com/uc?id=%s&export=download", google_doc_id), stringsAsFactors = FALSE)

```

If you browse this dataframe, you'll see that it not only includes the text of the blog posts, but also the names of the blog, the day of the year on which the blog post was produced, and a "conservative/liberal" label for each blog. We will use these variables later to demonstrate the power of meta-data for topic modeling.

Before we get into structural topic modeling, let's try out the `stm` package's text pre-processing functions. The `textProcessor` function automatically removes a) punctuation; b) stop words; c) numbers, and d) stems each word. If you need a refresher on why these steps are important, see my previous tutorial entitled "Basic Text Analysis." The function requires us to specify the part of the dataframe where the documents we want to analyze are (ours are called `documents`), and it also requires us to name the dataset where the rest of the meta data live (`poliblogs`).

```{r}
library(stm)
processed <- textProcessor(poliblogs$documents, metadata = poliblogs)
```

Somewhat unusually, the `stm` package also requires us to store the documents, meta data, and "vocab"---or total list of words described in the documents---in separate objects (see code below). The first line of code eliminates both extremely common terms and extremely rare terms, as is common practice in topic modeling, since such terms make word-topic assignment much more difficult.

```{r} 
out <- prepDocuments(processed$documents, processed$vocab, processed$meta)
docs <- out$documents
vocab <- out$vocab
meta <-out$meta
```

Before we run our first model, we have to make another decision about the number of topics we might expect to find in the corpus. Let's start out with 10. We also need to specify how we want to use the meta data. This model uses both the "rating" variable (that describes whether the blog is liberal or conservative) as well as the day or date variable to improve topic classification. Note that the choice of variables used at this stage can be very consequential-- in this case, we may fail to identify certain topics that appear on both liberal and conservative blogs (or wrongly conclude that they are separate issues).

Before we run the model, readers should also note that the STM package also has an argument that allows one to specify the type of initialization or randomization that should be used---in this case we are using spectral initialization, which has several advantages over a random seed that are discussed in the paper linked above.

```{r, message=FALSE, warning=FALSE}
First_STM <- stm(documents = out$documents, vocab = out$vocab,
              K = 10, prevalence =~ rating + s(day) ,
              max.em.its = 75, data = out$meta,
              init.type = "Spectral", verbose = FALSE)
```

You may notice that this code takes quite a while to run depending upon your machine. Once again, we can begin to inspect our results by browsig the top words associated with each topic. The `stm` package has a useful function that visualizes these results called `plot`:

```{r}
plot(First_STM)
```

This visualization describes the prevalence of the topic within the entire corpus as well as the top three words associated with the topic. As in our earlier example, you may see that there are some topics that seem plausible, but many others that do not seem very coherent or meaningful. The `stm` package has another useful function called `findThoughts` which extracts passages from documents within the corpus that load high on topics specified by the user.

```{r}
findThoughts(First_STM, texts = poliblogs$documents,
     n = 2, topics = 3)
```


**Choosing a value for k**

The `stm` package has a useful function called `searchK` which allows the user to specify a range of values for `k`, runs STM models for each value of 'k', and then outputs multiple goodness-of-fit measures that are very useful in identifying a range of values of `k` that provide the best fit for the data. The syntax of this function is very similar to the `stm` function, except that the user specifies a range for `k` as one of the arguments. In the code below, we search all values of `k` between 7 and 10.

```{r, message=FALSE, warning=FALSE, echo=TRUE, results='hide'}
findingk <- searchK(out$documents, out$vocab, K = c(10:30),
 prevalence =~ rating + s(day), data = meta, verbose=FALSE)

plot(findingk)
```

The next step is to plot the various fit measures:



Once again, readers should note that these measures are very imperfect, and are not a superior alternative to human validation of the topic models by carefully inspecting not only the top words associated with each document, but also conducting more focused analyses of the documents themselves.


## Working with meta-data

One of the principal advantages of STM is that one can examine the relationship between topics and various covariates of interest. Here we use the `estimateEffect` function to examine the relationship between the liberal/conservative `rating` variable and the first 10 topics, as well as time (`day`).

```{r, message=FALSE, warning=FALSE}
predict_topics<-estimateEffect(formula = 1:10 ~ rating + s(day), stmobj = First_STM, metadata = out$meta, uncertainty = "Global")
```

Once we have the model, we can plot the relationships. The code below picks three topics and plots them according to their association with the liberal/conservative `rating` variable.

```{r}
plot(predict_topics, covariate = "rating", topics = c(3, 5, 9),
 model = First_STM, method = "difference",
 cov.value1 = "Liberal", cov.value2 = "Conservative",
 xlab = "More Conservative ... More Liberal",
 main = "Effect of Liberal vs. Conservative",
 xlim = c(-.1, .1), labeltype = "custom",
 custom.labels = c('Topic 3', 'Topic 5','Topic 9'))

```

We can also plot change in the prevalence of topic over time. The code below plots change in the prevalence of topic 3.

```{r}
plot(predict_topics, "day", method = "continuous", topics = 3,
model = z, printlegend = FALSE, xaxt = "n", xlab = "Time (2008)")
monthseq <- seq(from = as.Date("2008-01-01"),
to = as.Date("2008-12-01"), by = "month")
monthnames <- months(monthseq)
axis(1,at = as.numeric(monthseq) - min(as.numeric(monthseq)),
labels = monthnames)

```


## Limitations of topic models

Topic models have become a standard tool within quantitative text analysis for many different reasons. Topic models can be much more useful than simple word frequency or dictionary based approaches depending upon the use case. Topic models tend to produce the best results when applied to texts that are not too short (such as tweets), and those that have a consistent structure. 

At the same time, topic models have a number of important limitations. To begin, the term "topic" is somewhat ambigious, and by now it is perhaps clear that topic models will not produce highly nuanced classification of texts. Second, topic models can easily be abused if they are wrongly understood as an objective representation of the meaning of a text. Once again, these tools might be more accurately be described as "tools for reading." The results of topic models should not be over-interpreted unless the researcher has strong theoretical apriori about the number of topics in a given corpus, or if the researcher has carefully validated the results of a topic model using both the quantitative and qualitative techniques described above.

